name: CI Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:latest
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-mock apache-airflow

    - name: Create artifact directories
      run: |
        mkdir -p artifacts/data_ingestion
        mkdir -p artifacts/data_validation
        mkdir -p artifacts/data_transformation
        mkdir -p artifacts/model_trainer
        mkdir -p artifacts/model_evaluation

    - name: Run ML Pipeline Tests
      env:
        PYTHONPATH: ${{ github.workspace }}
      run: |
        pytest tests/test_pipeline.py -v

    - name: Run ETL Pipeline Tests
      env:
        PYTHONPATH: ${{ github.workspace }}
        AIRFLOW_HOME: ${{ github.workspace }}/airflow
        POSTGRES_USER: postgres
        POSTGRES_PASSWORD: postgres
        POSTGRES_DB: test_db
        POSTGRES_HOST: localhost
      run: |
        mkdir -p airflow/dags
        cp dags/etl.py airflow/dags/
        airflow db init
        pytest tests/test_etl.py -v

    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: artifacts/